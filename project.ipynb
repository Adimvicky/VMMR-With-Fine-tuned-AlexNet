{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "COMP 6915-W25 Final Project\n",
    "Vehicle Make and Model Recognition using Fine-Tuned AlexNet\n",
    "Team: Victor Onwosi, Esther Ukpe, Jager Cooper\n",
    "\n",
    "This notebook implements a VMMR system using FastAI and AlexNet.\n",
    "It includes: dataset setup, transfer learning, evaluation, and visualization.\n",
    "\n",
    "Expected Folder Structure:\n",
    "- dataset/train/\n",
    "- dataset/valid/\n",
    "- visualizations/\n",
    "- models/\n",
    "\"\"\"\n",
    "# --------------------------------------\n",
    "# ‚úÖ STEP 1: Install fastai (latest)\n",
    "# --------------------------------------\n",
    "%pip install -U fastai\n",
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------\n",
    "# ‚úÖ STEP 2: Imports\n",
    "# --------------------------------------\n",
    "from fastai.vision.all import *\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.models import alexnet\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Local paths\n",
    "base_dir = Path(\".\")\n",
    "data_dir = base_dir / \"dataset\"\n",
    "models_dir = base_dir / \"models\"\n",
    "visual_dir = base_dir / \"visualizations\"\n",
    "\n",
    "# Create output dirs\n",
    "models_dir.mkdir(parents=True, exist_ok=True)\n",
    "visual_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ===============================\n",
    "# ‚úÖ STEP 1: Load Data\n",
    "# ===============================\n",
    "dls = ImageDataLoaders.from_folder(\n",
    "    data_dir,\n",
    "    train='train',\n",
    "    valid='valid',\n",
    "    item_tfms=Resize(224),\n",
    "    batch_tfms=[\n",
    "        *aug_transforms(\n",
    "            do_flip=True,\n",
    "            flip_vert=True,\n",
    "            max_rotate=5.0,\n",
    "            max_zoom=1.1,\n",
    "            max_lighting=0.2,\n",
    "            max_warp=0.2,\n",
    "            p_affine=0.75,\n",
    "            p_lighting=0.75\n",
    "        ),\n",
    "        Normalize.from_stats(*imagenet_stats)\n",
    "    ],\n",
    "    bs=32\n",
    ")\n",
    "\n",
    "# ===============================\n",
    "# üì∑ STEP 2: Show & Save Sample Batch\n",
    "# ===============================\n",
    "dls.show_batch(max_n=9, figsize=(8,6))\n",
    "plt.savefig(visual_dir / 'sample_batch.png')\n",
    "plt.close()\n",
    "\n",
    "# ===============================\n",
    "# üß† STEP 3: Create Learner (AlexNet)\n",
    "# ===============================\n",
    "learn = vision_learner(dls, models.alexnet, metrics=accuracy, pretrained=True)\n",
    "\n",
    "# ===============================\n",
    "# üéØ STEP 4: Fine-tune Model (50 epochs)\n",
    "# Save best model based on accuracy\n",
    "# ===============================\n",
    "\n",
    "# Step: Run learning rate finder\n",
    "lr_finder = learn.lr_find()\n",
    "lr_val = lr_finder.valley\n",
    "print(f\"‚úÖ Suggested Learning Rate (valley): {lr_val:.2e}\")\n",
    "\n",
    "# Plot with labeled valley\n",
    "plt.figure(figsize=(8,5))\n",
    "learn.recorder.plot_lr_find()\n",
    "plt.axvline(lr_val, color='red', linestyle='--', label=f'Valley: {lr_val:.2e}')\n",
    "plt.legend()\n",
    "plt.title('Learning Rate Finder with Valley Marked')\n",
    "plt.grid(True)\n",
    "plt.savefig(visual_dir / 'lr_find_plot_labeled.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "\n",
    "learn.fine_tune(\n",
    "    50,\n",
    "    base_lr=lr_val,\n",
    "    cbs=[\n",
    "        SaveModelCallback(monitor='accuracy', fname='best_model'),\n",
    "        EarlyStoppingCallback(monitor='accuracy', patience=8)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Plot training and validation accuracy over epochs\n",
    "metrics_df = pd.DataFrame(learn.recorder.values, columns=['train_loss', 'valid_loss', 'accuracy'])\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(metrics_df['accuracy'], label='Validation Accuracy', marker='o')\n",
    "plt.title('Validation Accuracy Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.savefig(visual_dir / 'val_accuracy_over_epochs.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# ===============================\n",
    "# üíæ STEP 5: Save Final and Best Model\n",
    "# ===============================\n",
    "learn.export(models_dir / 'final_alexnet.pkl')\n",
    "print(f\"‚úÖ Final model exported to: {models_dir / 'final_alexnet.pkl'}\")\n",
    "\n",
    "learn.load('best_model')  # Load the best model before evaluation/export\n",
    "learn.export(models_dir / 'best_alexnet.pkl')\n",
    "print(f\"‚úÖ Best model exported to: {models_dir / 'best_alexnet.pkl'}\")\n",
    "\n",
    "# ===============================\n",
    "# üìä STEP 6: Save Training Curve and Metrics CSV\n",
    "# ===============================\n",
    "learn.recorder.plot_loss()\n",
    "plt.savefig(visual_dir / 'train_loss.png')\n",
    "plt.close()\n",
    "\n",
    "# Plot both train and validation loss curves\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(metrics_df['train_loss'], label='Train Loss', marker='o')\n",
    "plt.plot(metrics_df['valid_loss'], label='Validation Loss', marker='o')\n",
    "plt.title('Loss Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.savefig(visual_dir / 'train_vs_val_loss.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# Save all metrics (train_loss, valid_loss, accuracy)\n",
    "metrics_df = pd.DataFrame(learn.recorder.values, columns=['train_loss', 'valid_loss', 'accuracy'])\n",
    "metrics_df.to_csv(visual_dir / 'metrics_over_epochs.csv', index=False)\n",
    "print(f\"‚úÖ Metrics CSV saved to: {visual_dir / 'metrics_over_epochs.csv'}\")\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# üîç STEP 7: Evaluate & Visualize\n",
    "# ===============================\n",
    "acc = learn.validate()[1]\n",
    "print(f\"‚úÖ Final Accuracy (best model): {acc:.4f}\")\n",
    "\n",
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "\n",
    "interp.plot_confusion_matrix(figsize=(10,10))\n",
    "plt.savefig(visual_dir / 'confusion_matrix.png')\n",
    "plt.close()\n",
    "try:\n",
    "    interp.plot_top_losses(9, nrows=3)\n",
    "    plt.savefig(visual_dir / 'top_losses.png')\n",
    "    plt.close()\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Failed to save top_losses.png: {e}\")\n",
    "\n",
    "# Show sample predictions (correct and incorrect)\n",
    "try:\n",
    "    interp.plot_top_losses(16, figsize=(12,12))\n",
    "    plt.savefig(visual_dir / 'top_losses_examples.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Failed to save top_losses_examples.png: {e}\")\n",
    "\n",
    "# Show a batch with predictions\n",
    "try:\n",
    "    learn.show_results(max_n=9, figsize=(10,8))\n",
    "    plt.savefig(visual_dir / 'sample_predictions.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Failed to save sample_predictions.png: {e}\")\n",
    "\n",
    "preds, targs = learn.get_preds()\n",
    "\n",
    "# Calculate class-wise accuracy\n",
    "acc_per_class = []\n",
    "for c in range(len(dls.vocab)):\n",
    "    mask = targs == c\n",
    "    if mask.sum() > 0:  # Avoid division by zero\n",
    "        class_acc = (preds[mask].argmax(dim=1) == targs[mask]).float().mean().item()\n",
    "    else:\n",
    "        class_acc = 0.0\n",
    "    acc_per_class.append((dls.vocab[c], class_acc))\n",
    "\n",
    "# Create and save accuracy DataFrame\n",
    "acc_df = pd.DataFrame(acc_per_class, columns=['Class', 'Accuracy'])\n",
    "acc_df.to_csv(visual_dir / 'classwise_accuracy.csv', index=False)\n",
    "\n",
    "report_dict = classification_report(\n",
    "    targs.numpy(),\n",
    "    preds.argmax(dim=1).numpy(),\n",
    "    target_names=dls.vocab,\n",
    "    output_dict=True\n",
    ")\n",
    "\n",
    "report_df = pd.DataFrame(report_dict).transpose()\n",
    "report_df.to_csv(visual_dir / 'classification_report.csv')\n",
    "\n",
    "# Generate confusion matrix\n",
    "cm = interp.confusion_matrix()\n",
    "\n",
    "# Create confusion matrix DataFrame\n",
    "df_cm = pd.DataFrame(cm,  # Convert tensor to numpy array\n",
    "                    index=dls.vocab,\n",
    "                    columns=dls.vocab)\n",
    "df_cm.to_csv(visual_dir / 'confusion_matrix_data.csv')\n",
    "\n",
    "# Plot top losses with modern formatting\n",
    "try:\n",
    "    interp.plot_top_losses(20, nrows=5, figsize=(15,10))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(visual_dir / 'top_losses_per_class.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Failed to save top_losses_per_class.png: {e}\")\n",
    "\n",
    "# Create normalized confusion matrix\n",
    "try:\n",
    "    interp.plot_confusion_matrix(normalize=True, figsize=(15,15))\n",
    "    plt.savefig(visual_dir / 'confusion_matrix_normalized.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Failed to save confusion_matrix_normalized.png: {e}\")\n",
    "\n",
    "# Create classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(targs.numpy(), preds.argmax(dim=1).numpy(), target_names=dls.vocab))\n",
    "\n",
    "print(\"‚úÖ All steps completed. Outputs saved to 'visualizations/' and 'models/'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
